{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# GPU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import copy\n",
    "import math\n",
    "import time\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.autograd import Variable\n",
    "\n",
    "import torchtext"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import copy\n",
    "\n",
    "def make_model(src_vocab, trg_vocab, d_embed=512, n_layer=6, d_model=512, n_head=8):\n",
    "    multi_head_attention_layer = MultiHeadAttentionLayer(d_embed = d_embed,\n",
    "                                                         d_model = d_model,\n",
    "                                                         n_head = n_head,\n",
    "                                                         qkv_fc_layer = nn.Linear(d_embed, d_model),\n",
    "                                                         fc_layer = nn.Linear(d_model, d_embed))\n",
    "    model = Transformer(src_vocab = src_vocab, \n",
    "                        trg_vocab = trg_vocab, \n",
    "                        src_embed = TransformerEmbedding(Embedding(d_embed, src_vocab), PositionalEncoding(d_embed)), \n",
    "                        trg_embed = TransformerEmbedding(Embedding(d_embed, trg_vocab), PositionalEncoding(d_embed)),\n",
    "                        encoder = Encoder(sub_layer = EncoderLayer(multi_head_attention_layer = copy.deepcopy(multi_head_attention_layer).to(device),\n",
    "                                                                   fc_layer = nn.Linear(d_model, d_model),\n",
    "                                                                   residual_connection = True),\n",
    "                                          n_layer = n_layer),\n",
    "                        decoder = Decoder(sub_layer = DecoderLayer(multi_head_attention_layer = copy.deepcopy(multi_head_attention_layer).to(device),\n",
    "                                                                  masked_multi_head_attention_layer = copy.deepcopy(multi_head_attention_layer).to(device),\n",
    "                                                                  fc_layer = nn.Linear(d_model, d_model),\n",
    "                                                                  residual_connection = True),\n",
    "                                          n_layer = n_layer))\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cuda:0')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Vocab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### from torchtext.datasets import Multi30k\n",
    "from torchtext.data import Field, BucketIterator, interleave_keys\n",
    "\n",
    "def itos(field, batch):  # batch에서 원본 sentence 얻는 함수\n",
    "    with torch.cuda.device_of(batch):\n",
    "        #batch = batch.T.tolist()\n",
    "        batch = batch.tolist()\n",
    "    batch = [[field.vocab.itos[ind] for ind in ex] for ex in batch]  # denumericalize\n",
    "    \n",
    "    def trim(s, t):  # 현재 token ~ <EOS> token 사이의 문장 return\n",
    "        sentence = []\n",
    "        for w in s:\n",
    "            if w == t:\n",
    "                break\n",
    "            sentence.append(w)\n",
    "        return sentence\n",
    "\n",
    "    batch = [trim(ex, field.eos_token) for ex in batch]  # batch를 문장으로 \n",
    "    \n",
    "    def filter_special(tok):\n",
    "        return tok not in (field.init_token, field.pad_token)\n",
    "\n",
    "    batch = [list(filter(filter_special, ex)) for ex in batch]\n",
    "    return batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "SRC = Field(tokenize = \"spacy\",\n",
    "            tokenizer_language = \"de\",\n",
    "            init_token = '<sos>',\n",
    "            eos_token = '<eos>',\n",
    "            lower = True)\n",
    "\n",
    "TRG = Field(tokenize = \"spacy\",\n",
    "            tokenizer_language = \"en\",\n",
    "            init_token = '<sos>',\n",
    "            eos_token = '<eos>',\n",
    "            lower = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchtext.datasets import Multi30k\n",
    "\n",
    "train_data, valid_data, test_data = Multi30k.splits(exts = ('.de', '.en'), fields = (SRC, TRG))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "SRC.build_vocab(train_data)\n",
    "TRG.build_vocab(train_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Transformer(nn.Module):\n",
    "    \n",
    "    def __init__(self, src_vocab, trg_vocab, src_embed, trg_embed, encoder, decoder, fc_layer):\n",
    "        super(Transformer, self).__init__()\n",
    "        self.src_vocab = src_vocab\n",
    "        self.trg_vocab = trg_vocab\n",
    "        self.src_embed = src_embed\n",
    "        self.trg_embed = trg_embed\n",
    "        self.encoder = encoder\n",
    "        self.decoder = decoder\n",
    "        self.fc_layer = fc_layer\n",
    "        \n",
    "    def forward(self, src, trg, src_mask, trg_mask):\n",
    "        out = self.encode(src, src_mask)\n",
    "        out = self.decode(trg, trg_mask, out) # Decoder's src: Encoder's output\n",
    "        out = self.fc_layer(out)\n",
    "        out = F.log_softmax(out, dim=-1)\n",
    "        return out\n",
    "    \n",
    "    def encode(self, x, mask):\n",
    "        out = self.encoder(self.src_embed(x), mask)\n",
    "        return out\n",
    "    \n",
    "    def decode(self, x, mask, encoder_output):\n",
    "        out = self.decoder(self.trg_embed(x), mask, encoder_output)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Encoder(nn.Module):\n",
    "    \n",
    "    def __init__(self, sub_layer, n_layer):\n",
    "        super(Encoder, self).__init__()\n",
    "        self.layers = []\n",
    "        for i in range(n_layer):\n",
    "            self.layers.append(copy.deepcopy(sub_layer))\n",
    "    \n",
    "    def forward(self, x, mask):\n",
    "        out = x\n",
    "        for layer in self.layers: \n",
    "            out = layer(out, mask)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Decoder(nn.Module):\n",
    "    \n",
    "    def __init__(self, sub_layer, n_layer):\n",
    "        super(Decoder, self).__init__()\n",
    "        self.layers = []\n",
    "        for i in range(n_layer):\n",
    "            self.layers.append(copy.deepcopy(sub_layer))\n",
    "    \n",
    "    def forward(self, x, mask, encoder_output):\n",
    "        out = x\n",
    "        for layer in self.layers: \n",
    "            out = layer(x, mask, encoder_output)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "class EncoderLayer(nn.Module):\n",
    "    \n",
    "    def __init__(self, multi_head_attention_layer, fc_layer, residual_connection=True):\n",
    "        super(EncoderLayer, self).__init__()\n",
    "        if residual_connection:\n",
    "            self.multi_head_attention_layer = ResidualConnectionLayer(multi_head_attention_layer)\n",
    "            self.fc_layer = ResidualConnectionLayer(fc_layer)\n",
    "        else:\n",
    "            self.multi_head_attention_layer = multi_head_attention_layer\n",
    "            self.fc_layer = fc_layer\n",
    "    \n",
    "    def forward(self, x, mask):\n",
    "        out = self.multi_head_attention_layer(query=x, key=x, value=x, mask=None)\n",
    "        out = self.fc_layer(x=out)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DecoderLayer(nn.Module):\n",
    "    \n",
    "    def __init__(self, multi_head_attention_layer, masked_multi_head_attention_layer, fc_layer, residual_connection=True):\n",
    "        super(DecoderLayer, self).__init__()\n",
    "        if residual_connection:\n",
    "            self.masked_multi_head_attention_layer = ResidualConnectionLayer(multi_head_attention_layer)\n",
    "            self.multi_head_attention_layer = ResidualConnectionLayer(masked_multi_head_attention_layer)\n",
    "            self.fc_layer = ResidualConnectionLayer(fc_layer)\n",
    "        else:\n",
    "            self.masked_multi_head_attention_layer = multi_head_attention_layer\n",
    "            self.multi_head_attention_layer = masked_multi_head_attention_layer\n",
    "            self.fc_layer = fc_layer\n",
    "    \n",
    "    def forward(self, x, mask, encoder_output):\n",
    "        out = self.masked_multi_head_attention_layer(query=x, key=x, value=x, mask=mask)\n",
    "        out = self.multi_head_attention_layer(query=x, key=encoder_output, value=encoder_output)\n",
    "        out = self.fc_layer(x=out)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MultiHeadAttentionLayer(nn.Module):\n",
    "    \n",
    "    def __init__(self, d_embed, d_model, n_head, qkv_fc_layer, fc_layer):\n",
    "        super(MultiHeadAttentionLayer, self).__init__()\n",
    "        self.d_embed = d_embed\n",
    "        self.d_model = d_model\n",
    "        self.n_head = n_head\n",
    "        self.query_fc_layer = copy.deepcopy(qkv_fc_layer)\n",
    "        self.key_fc_layer = copy.deepcopy(qkv_fc_layer)\n",
    "        self.value_fc_layer = copy.deepcopy(qkv_fc_layer)\n",
    "        self.fc_layer = copy.deepcopy(fc_layer)\n",
    "    \n",
    "    def forward(self, query, key, value, mask=None):\n",
    "        # query, key, value's shape: (n_batch, seq_len, d_embed)\n",
    "        n_batch = query.shape[0]\n",
    "        \n",
    "        # reshape (n_batch, seq_len, d_embed) to (n_batch, n_head, seq_len, d_k)\n",
    "        def transform(x, fc_layer):\n",
    "            # x's shape: (n_batch, seq_len, d_embed)\n",
    "            out = fc_layer(x) # d_embed -> d_model, out's shape: (n_batch, seq_len, d_model)\n",
    "            out = out.view(n_batch, -1, self.n_head, self.d_model//self.n_head) # out's shape: (n_batch, seq_len, n_head, d_k) notice: d_k == d_model//n_head\n",
    "            out = out.transpose(1, 2) # out's shape: (n_batch, n_head, seq_len, d_k)\n",
    "            return out\n",
    "        \n",
    "        query = transform(query, self.query_fc_layer)      # query, key, value's shape: (n_batch, n_head, seq_len, d_k)\n",
    "        key = transform(key, self.key_fc_layer)\n",
    "        value = transform(value, self.value_fc_layer)\n",
    "        \n",
    "        if mask is not None:\n",
    "            mask = mask.unsqueeze(1)\n",
    "        \n",
    "        out = self.calculate_attention(query, key, value, mask) # out's shape: (n_batch, n_head, seq_len, d_k)\n",
    "        out = out.transpose(1, 2)  # out's shape: (n_batch, seq_len, n_head, d_k)\n",
    "        out = out.contiguous().view(n_batch, -1, self.d_model)  # out's shape: (n_batch, seq_len, d_model)\n",
    "        out = self.fc_layer(out)  # d-model -> d_embed, out's shape: (n_batch, seq_len, d_embed)\n",
    "        return out\n",
    "    \n",
    "    @staticmethod\n",
    "    def calculate_attention(query, key, value, mask): \n",
    "        d_k = key.size(-1) # query, key, value's shape: (n_batch, n_head, seq_len, d_k)\n",
    "        score = torch.matmul(query, key.transpose(-2, -1)) # Q x K^T\n",
    "        score = score / math.sqrt(d_k)  # scaling\n",
    "        if mask is not None:\n",
    "            score = score.masked_fill(mask==0, -1e9)  # masking (Decoder's Masked Multi-Attention Layer)\n",
    "        out = F.softmax(score, dim = -1) # get softmax score\n",
    "        out = torch.matmul(out, value) # score x V\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ResidualConnectionLayer(nn.Module):\n",
    "    def __init__(self, sub_layer):\n",
    "        super(ResidualConnectionLayer, self).__init__()\n",
    "        self.sub_layer = sub_layer\n",
    "    \n",
    "    def forward(self, **kwargs):\n",
    "        if 'x' in kwargs.keys():\n",
    "            x = kwargs['x']\n",
    "            out = x + self.sub_layer(x)\n",
    "        elif 'query' in kwargs.keys():\n",
    "            x = kwargs['query']\n",
    "            out = x + self.sub_layer(**kwargs)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PositionalEncoding(nn.Module):\n",
    "    def __init__(self, d_embed, max_seq_len=5000):\n",
    "        super(PositionalEncoding, self).__init__()\n",
    "        encoding = torch.zeros(max_seq_len, d_embed)\n",
    "        position = torch.arange(0, max_seq_len).unsqueeze(1)\n",
    "        div_term = torch.exp(torch.arange(0, d_embed, 2) * -(math.log(10000.0) / d_embed))\n",
    "        encoding[:, 0::2] = torch.sin(position * div_term)\n",
    "        encoding[:, 1::2] = torch.cos(position * div_term)\n",
    "        encoding = encoding.unsqueeze(0)\n",
    "        self.encoding = encoding\n",
    "        \n",
    "    def forward(self, x):\n",
    "        out = x + Variable(self.encoding[:, :x.size(1)], requires_grad=False).to(device)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Embedding(nn.Module):\n",
    "    def __init__(self, d_embed, vocab):\n",
    "        super(Embedding, self).__init__()\n",
    "        self.embedding = nn.Embedding(len(vocab), d_embed)\n",
    "        self.vocab = vocab\n",
    "        self.d_embed = d_embed\n",
    "    \n",
    "    def forward(self, x):\n",
    "        out = self.embedding(x) * math.sqrt(self.d_embed)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TransformerEmbedding(nn.Module):\n",
    "    def __init__(self, embedding, positional_encoding):\n",
    "        super(TransformerEmbedding, self).__init__()\n",
    "        self.embedding = nn.Sequential(embedding, positional_encoding)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        out = self.embedding(x)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_model(src_vocab, trg_vocab, d_embed=512, n_layer=6, d_model=512, n_head=8):\n",
    "    multi_head_attention_layer = MultiHeadAttentionLayer(d_embed = d_embed,\n",
    "                                                         d_model = d_model,\n",
    "                                                         n_head = n_head,\n",
    "                                                         qkv_fc_layer = nn.Linear(d_embed, d_model),\n",
    "                                                         fc_layer = nn.Linear(d_model, d_embed))\n",
    "    model = Transformer(src_vocab = src_vocab, \n",
    "                        trg_vocab = trg_vocab, \n",
    "                        src_embed = TransformerEmbedding(Embedding(d_embed, src_vocab), PositionalEncoding(d_embed)), \n",
    "                        trg_embed = TransformerEmbedding(Embedding(d_embed, trg_vocab), PositionalEncoding(d_embed)),\n",
    "                        encoder = Encoder(sub_layer = EncoderLayer(multi_head_attention_layer = copy.deepcopy(multi_head_attention_layer).to(device),\n",
    "                                                                   fc_layer = nn.Linear(d_model, d_model),\n",
    "                                                                   residual_connection = True),\n",
    "                                          n_layer = n_layer),\n",
    "                        decoder = Decoder(sub_layer = DecoderLayer(multi_head_attention_layer = copy.deepcopy(multi_head_attention_layer).to(device),\n",
    "                                                                  masked_multi_head_attention_layer = copy.deepcopy(multi_head_attention_layer).to(device),\n",
    "                                                                  fc_layer = nn.Linear(d_model, d_model),\n",
    "                                                                  residual_connection = True),\n",
    "                                          n_layer = n_layer),\n",
    "                        fc_layer = nn.Linear(d_model, len(trg_vocab)).to(device))\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dataset, Batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### from torchtext.datasets import Multi30k\n",
    "from torchtext.data import Field, BucketIterator, interleave_keys\n",
    "\n",
    "def itos(field, batch):  # batch에서 원본 sentence 얻는 함수\n",
    "    with torch.cuda.device_of(batch):\n",
    "        #batch = batch.T.tolist()\n",
    "        batch = batch.tolist()\n",
    "    batch = [[field.vocab.itos[ind] for ind in ex] for ex in batch]  # denumericalize\n",
    "    \n",
    "    def trim(s, t):  # 현재 token ~ <EOS> token 사이의 문장 return\n",
    "        sentence = []\n",
    "        for w in s:\n",
    "            if w == t:\n",
    "                break\n",
    "            sentence.append(w)\n",
    "        return sentence\n",
    "\n",
    "    batch = [trim(ex, field.eos_token) for ex in batch]  # batch를 문장으로 \n",
    "    \n",
    "    def filter_special(tok):\n",
    "        return tok not in (field.init_token, field.pad_token)\n",
    "\n",
    "    batch = [list(filter(filter_special, ex)) for ex in batch]\n",
    "    return batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "BATCH_SIZE = 128\n",
    "\n",
    "# get iterator (train, valid, test)\n",
    "train_iterator, valid_iterator, test_iterator = BucketIterator.splits(\n",
    "    (train_data, valid_data, test_data),\n",
    "    batch_size = BATCH_SIZE,\n",
    "    device = device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def subsequent_mask(size):\n",
    "    \"Mask out subsequent positions.\"\n",
    "    attn_shape = (1, size, size)\n",
    "    subsequent_mask = np.triu(np.ones(attn_shape), k=1).astype('uint8')  # masking with upper triangle\n",
    "    return torch.from_numpy(subsequent_mask) == 0 # reverse (masking=False, non-masking=True)\n",
    "\n",
    "class Batch:\n",
    "    \n",
    "    \"Object for holding a batch of data with masking during training.\" \n",
    "    def __init__(self, src, trg=None, pad=1):\n",
    "        self.src = src.T\n",
    "        self.src_mask = (src != pad).unsqueeze(-2)  # source mask, <pad>: False, other tokens: True\n",
    "        if trg is not None:\n",
    "            self.trg = trg.T[:, :-1]  # target sentence 0 ~ -1\n",
    "            self.trg_y = trg.T[:, 1:]  # target sentence 1 ~ end\n",
    "            self.trg_mask = self.make_std_mask(self.trg, pad) # target mask\n",
    "            self.ntokens = (self.trg_y != pad).data.sum() # number of tokens\n",
    "    \n",
    "    @staticmethod\n",
    "    def make_std_mask(tgt, pad):\n",
    "        \"Create a mask to hide padding and future words.\"\n",
    "        tgt_mask = (tgt != pad).unsqueeze(-2) # <pad>: False, other tokens: True, reshape (batch_size, seq_len) -> (batch_size, 1, seq_len)\n",
    "        tgt_mask = tgt_mask & Variable(subsequent_mask(tgt.size(-1)).type_as(tgt_mask.data)) # not <pad> && non-masking: True, others: False\n",
    "        return tgt_mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([128, 24]) torch.Size([24, 1, 128]) torch.Size([128, 27]) torch.Size([128, 27, 27])\n",
      "src[0]:  ein mann in einem farbenfrohen outfit und mit hut steht in einer menschenmenge .\n",
      "\n",
      "trg[0]:  a man in a colorful outfit and hat is standing in a crowd .\n",
      "\n",
      "trg[1]:  three people in skiing gear are standing behind a \" no skiing \" sign .\n",
      "\n",
      "trg_y[0]:  a man in a colorful outfit and hat is standing in a crowd .\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# 데이터 확인\n",
    "\n",
    "pad_index = SRC.vocab[SRC.pad_token]\n",
    "\n",
    "for i, batch_without_mask in enumerate(train_iterator):\n",
    "    batch = Batch(batch_without_mask.src, batch_without_mask.trg, pad_index)\n",
    "    print(batch.src.shape, batch.src_mask.shape, batch.trg.shape, batch.trg_mask.shape)\n",
    "    \n",
    "    print('src[0]: ', ' '.join(itos(SRC, batch.src)[0]))\n",
    "    print()\n",
    "    \n",
    "    print('trg[0]: ', ' '.join(itos(TRG, batch.trg)[0]))\n",
    "    print()\n",
    "    \n",
    "    print('trg[1]: ', ' '.join(itos(TRG, batch.trg)[1]))\n",
    "    print()\n",
    "    \n",
    "    print('trg_y[0]: ', ' '.join(itos(TRG, batch.trg_y)[0]))\n",
    "    print()\n",
    "    break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tranining"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Transformer(\n",
      "  (src_embed): TransformerEmbedding(\n",
      "    (embedding): Sequential(\n",
      "      (0): Embedding(\n",
      "        (embedding): Embedding(18668, 512)\n",
      "      )\n",
      "      (1): PositionalEncoding()\n",
      "    )\n",
      "  )\n",
      "  (trg_embed): TransformerEmbedding(\n",
      "    (embedding): Sequential(\n",
      "      (0): Embedding(\n",
      "        (embedding): Embedding(9799, 512)\n",
      "      )\n",
      "      (1): PositionalEncoding()\n",
      "    )\n",
      "  )\n",
      "  (encoder): Encoder()\n",
      "  (decoder): Decoder()\n",
      "  (fc_layer): Linear(in_features=512, out_features=9799, bias=True)\n",
      ")\n",
      "19601991\n"
     ]
    }
   ],
   "source": [
    "model = make_model(SRC.vocab, TRG.vocab, d_embed=512, n_layer=6, d_model=512, n_head=8)\n",
    "model.to(device)\n",
    "print(model)\n",
    "\n",
    "# get num of parameters\n",
    "model_parameters = filter(lambda p: p.requires_grad, model.parameters())\n",
    "n_parameter = sum([np.prod(p.size()) for p in model_parameters])\n",
    "print(n_parameter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_epoch(data_iter, model, loss_compute, optimizer):\n",
    "    \"Standard Training and Logging Function\"\n",
    "    start = time.time()\n",
    "    total_tokens = 0\n",
    "    total_loss = 0\n",
    "    tokens = 0\n",
    "    pad_index = SRC.vocab[SRC.pad_token]\n",
    "\n",
    "    for i, batch_without_mask in enumerate(data_iter):\n",
    "        # mask 적용\n",
    "        batch = Batch(batch_without_mask.src, batch_without_mask.trg, pad_index)\n",
    "\n",
    "        batch.src = batch.src.to(device)\n",
    "        batch.trg = batch.trg.to(device)\n",
    "        batch.src_mask = batch.src_mask.to(device)\n",
    "        batch.trg_mask = batch.trg_mask.to(device)\n",
    "        out = model.forward(batch.src, batch.trg, batch.src_mask, batch.trg_mask)\n",
    "        loss = loss_compute(out.contiguous().transpose(-2, -1), batch.trg_y.contiguous())\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        total_loss += loss\n",
    "        total_tokens += batch.ntokens\n",
    "        tokens += batch.ntokens\n",
    "        if i % 50 == 1:\n",
    "            elapsed = time.time() - start\n",
    "            print(\"Epoch Step: %d Loss: %f Tokens per Sec: %f\" % (i, loss / batch.ntokens, tokens / elapsed))\n",
    "            start = time.time()\n",
    "            tokens = 0\n",
    "\n",
    "    return total_loss / total_tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch Step: 1 Loss: 0.070773 Tokens per Sec: 1221.677734\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-32-df9092cb6ce5>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mepoch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn_epoch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m     \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m     \u001b[0mrun_epoch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_iterator\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-31-aeb804957189>\u001b[0m in \u001b[0;36mrun_epoch\u001b[0;34m(data_iter, model, loss_compute, optimizer)\u001b[0m\n\u001b[1;32m     15\u001b[0m         \u001b[0mbatch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msrc_mask\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msrc_mask\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m         \u001b[0mbatch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrg_mask\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrg_mask\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 17\u001b[0;31m         \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msrc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msrc_mask\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrg_mask\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     18\u001b[0m         \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mloss_compute\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcontiguous\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtranspose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrg_y\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcontiguous\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m         \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-9-d4b52472030f>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, src, trg, src_mask, trg_mask)\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msrc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msrc_mask\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrg_mask\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 14\u001b[0;31m         \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mencode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msrc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msrc_mask\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     15\u001b[0m         \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdecode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrg_mask\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mout\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# Decoder's src: Encoder's output\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m         \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfc_layer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-9-d4b52472030f>\u001b[0m in \u001b[0;36mencode\u001b[0;34m(self, x, mask)\u001b[0m\n\u001b[1;32m     19\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mencode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmask\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 21\u001b[0;31m         \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mencoder\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msrc_embed\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmask\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     22\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mout\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    548\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    549\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 550\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    551\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    552\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-10-2909c72124d1>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x, mask)\u001b[0m\n\u001b[1;32m     10\u001b[0m         \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mlayer\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayers\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 12\u001b[0;31m             \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlayer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmask\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     13\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mout\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    548\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    549\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 550\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    551\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    552\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-12-c5adbfcbcc06>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x, mask)\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmask\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 13\u001b[0;31m         \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmulti_head_attention_layer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mquery\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmask\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     14\u001b[0m         \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfc_layer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mout\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    548\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    549\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 550\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    551\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    552\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-15-4c899b8c41a9>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, **kwargs)\u001b[0m\n\u001b[1;32m     10\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0;34m'query'\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeys\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m             \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'query'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 12\u001b[0;31m             \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msub_layer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     13\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mout\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    548\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    549\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 550\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    551\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    552\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-14-43ef1601f4ad>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, query, key, value, mask)\u001b[0m\n\u001b[1;32m     30\u001b[0m             \u001b[0mmask\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmask\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munsqueeze\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     31\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 32\u001b[0;31m         \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcalculate_attention\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mquery\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmask\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# out's shape: (n_batch, n_head, seq_len, d_k)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     33\u001b[0m         \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mout\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtranspose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# out's shape: (n_batch, seq_len, n_head, d_k)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     34\u001b[0m         \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mout\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcontiguous\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mview\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn_batch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0md_model\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# out's shape: (n_batch, seq_len, d_model)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-14-43ef1601f4ad>\u001b[0m in \u001b[0;36mcalculate_attention\u001b[0;34m(query, key, value, mask)\u001b[0m\n\u001b[1;32m     39\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mcalculate_attention\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mquery\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmask\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     40\u001b[0m         \u001b[0md_k\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# query, key, value's shape: (n_batch, n_head, seq_len, d_k)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 41\u001b[0;31m         \u001b[0mscore\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmatmul\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mquery\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtranspose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# Q x K^T\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     42\u001b[0m         \u001b[0mscore\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mscore\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0mmath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msqrt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0md_k\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# scaling\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     43\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mmask\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "lr = 0.01\n",
    "n_epoch = 5\n",
    "\n",
    "criterion = nn.NLLLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=lr, betas=(0.9, 0.98), eps=1e-9)\n",
    "\n",
    "for epoch in range(n_epoch):\n",
    "    model.train()\n",
    "    run_epoch(train_iterator, model, criterion, optimizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr = 0.01\n",
    "\n",
    "criterion = nn.NLLLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=lr, betas=(0.9, 0.98), eps=1e-9)\n",
    "\n",
    "@torch.no_grad()\n",
    "def evaluate(data_iter):\n",
    "    model.eval()\n",
    "    start = time.time()\n",
    "    total_tokens = 0\n",
    "    total_loss = 0\n",
    "    tokens = 0\n",
    "    pad_index = SRC.vocab[SRC.pad_token]\n",
    "\n",
    "    for i, batch_without_mask in enumerate(data_iter):\n",
    "        # mask 적용\n",
    "        batch = Batch(batch_without_mask.src, batch_without_mask.trg, pad_index)\n",
    "\n",
    "        batch.src = batch.src.to(device)\n",
    "        batch.trg = batch.trg.to(device)\n",
    "        batch.src_mask = batch.src_mask.to(device)\n",
    "        batch.trg_mask = batch.trg_mask.to(device)\n",
    "        out = model.forward(batch.src, batch.trg, batch.src_mask, batch.trg_mask)\n",
    "        loss = loss_compute(out.contiguous().transpose(-2, -1), batch.trg_y.contiguous())\n",
    "        optimizer.zero_grad()\n",
    "        total_loss += loss\n",
    "        total_tokens += batch.ntokens\n",
    "        tokens += batch.ntokens\n",
    "        if i % 50 == 1:\n",
    "            elapsed = time.time() - start\n",
    "            print(\"Epoch Step: %d Loss: %f Tokens per Sec: %f\" % (i, loss / batch.ntokens, tokens / elapsed))\n",
    "            start = time.time()\n",
    "            tokens = 0\n",
    "\n",
    "    print(\"Final: \", total_loss / total_tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluate(valid_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 325,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.3082, 0.0131, 0.1848, 0.0206, 0.4733],\n",
      "        [0.0952, 0.0534, 0.0903, 0.6993, 0.0617],\n",
      "        [0.0577, 0.2333, 0.1583, 0.5332, 0.0174]], grad_fn=<SoftmaxBackward>)\n",
      "tensor([1, 0, 4])\n",
      "tensor([4, 3, 3], grad_fn=<NotImplemented>)\n",
      "tensor(-0.0419, grad_fn=<NllLossBackward>)\n"
     ]
    }
   ],
   "source": [
    "m = nn.Softmax(dim=1)\n",
    "loss = nn.NLLLoss()\n",
    "input = torch.randn(3, 5, requires_grad=True)\n",
    "\n",
    "target = torch.tensor([1, 0, 4])\n",
    "softmax = m(input)\n",
    "output = loss(softmax, target)\n",
    "output.backward()\n",
    "\n",
    "print(softmax)\n",
    "print(target)\n",
    "print(torch.argmax(softmax, dim=1))\n",
    "print(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 324,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([5, 16, 10, 10])\n",
      "torch.Size([5, 4, 8, 8])\n",
      "torch.Size([5, 4, 8, 8])\n",
      "torch.Size([5, 8, 8])\n",
      "tensor(-0.2442, grad_fn=<NllLoss2DBackward>)\n"
     ]
    }
   ],
   "source": [
    "N, C = 5, 4\n",
    "loss = nn.NLLLoss()\n",
    "data = torch.randn(N, 16, 10, 10)\n",
    "conv = nn.Conv2d(16, C, (3,3))\n",
    "m = nn.Softmax(dim=1)\n",
    "c = conv(data)\n",
    "softmax = m(c)\n",
    "target = torch.empty(N, 8, 8, dtype=torch.long).random_(0,C)\n",
    "output = loss(softmax, target)\n",
    "output.backward()\n",
    "\n",
    "print(data.shape)\n",
    "print(c.shape)\n",
    "print(softmax.shape)\n",
    "print(target.shape)\n",
    "print(output)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
