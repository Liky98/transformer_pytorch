{"nbformat":4,"nbformat_minor":0,"metadata":{"accelerator":"GPU","colab":{"name":"transformer.ipynb","provenance":[],"collapsed_sections":["uFxX-YJyAIuW","bRO2B0zUAIub","McJYJOZtAIuZ","Um2wcEc1AIuf","gQdxLVbsRzKd"]},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.8.5"}},"cells":[{"cell_type":"code","metadata":{"id":"eoYunYmN9wu7"},"source":["import os\n","from google.colab import drive\n","drive.mount('/content/gdrive/', force_remount=True)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"uFxX-YJyAIuW"},"source":["# Setting"]},{"cell_type":"code","metadata":{"id":"ibCAumPY91Jg"},"source":["%cd \"/content/gdrive/My Drive/ML\"\n","%ls"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"UyJ1ECYrJ7bS"},"source":["!pip uninstall --y torch torchtext\n","!pip install --pre torchtext -f https://download.pytorch.org/whl/nightly/cu101/torch_nightly.html"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"jXexalUXAfVY"},"source":["!pip install spacy  # spacy tokenizer\n","!python -m spacy download en # src language\n","!python -m spacy download de # trg language\n","!pip install GPUtil # for print GPU usage"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"mFFUmUM3AIuY"},"source":["import copy\n","import math\n","import time\n","import numpy as np\n","\n","import torch\n","import torch.nn as nn\n","import torch.nn.functional as F\n","import torch.optim as optim\n","from torch.autograd import Variable\n","import torchtext"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"_5PsKFXmYqtM"},"source":["print(torch.backends.cudnn.enabled)\n","print(torch.cuda.is_available())\n","\n","device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n","print(device)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"bRO2B0zUAIub"},"source":["# Model"]},{"cell_type":"code","metadata":{"id":"AMG3z7rUAIub"},"source":["class Transformer(nn.Module):\n","    \n","    def __init__(self, src_embed, trg_embed, encoder, decoder, fc_layer):\n","        super(Transformer, self).__init__()\n","        self.src_embed = src_embed\n","        self.trg_embed = trg_embed\n","        self.encoder = encoder\n","        self.decoder = decoder\n","        self.fc_layer = fc_layer\n","        \n","    def forward(self, src, trg, src_mask, trg_mask):\n","        out = self.encode(src, src_mask)\n","        out = self.decode(trg, trg_mask, out, src_mask) # Decoder's src: Encoder's output\n","        out = self.fc_layer(out)\n","        out = F.log_softmax(out, dim=-1)\n","        return out\n","    \n","    def encode(self, x, mask):\n","        out = self.encoder(self.src_embed(x), mask)\n","        return out\n","    \n","    def decode(self, x, mask, encoder_output, encoder_mask):\n","        out = self.decoder(self.trg_embed(x), mask, encoder_output, encoder_mask)\n","        return out"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"3D8JowV9AIub"},"source":["class Encoder(nn.Module):\n","    \n","    def __init__(self, sub_layer, n_layer):\n","        super(Encoder, self).__init__()\n","        self.layers = []\n","        for i in range(n_layer):\n","            self.layers.append(copy.deepcopy(sub_layer))\n","    \n","    def forward(self, x, mask):\n","        out = x\n","        for layer in self.layers: \n","            out = layer(out, mask)\n","        return out"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"LA13SOyvAIub"},"source":["class Decoder(nn.Module):\n","    \n","    def __init__(self, sub_layer, n_layer):\n","        super(Decoder, self).__init__()\n","        self.layers = []\n","        for i in range(n_layer):\n","            self.layers.append(copy.deepcopy(sub_layer))\n","    \n","    def forward(self, x, mask, encoder_output, encoder_mask):\n","        out = x\n","        for layer in self.layers: \n","            out = layer(x, mask, encoder_output, encoder_mask)\n","        return out"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"U59sCHXIAIub"},"source":["class EncoderLayer(nn.Module):\n","    \n","    def __init__(self, multi_head_attention_layer, position_wise_feed_forward_layer, norm_layer, dropout_rate):\n","        super(EncoderLayer, self).__init__()\n","        self.multi_head_attention_layer = ResidualConnectionLayer(multi_head_attention_layer, copy.deepcopy(norm_layer), dropout_rate)\n","        self.position_wise_feed_forward_layer = ResidualConnectionLayer(position_wise_feed_forward_layer, copy.deepcopy(norm_layer), dropout_rate)\n","    \n","    def forward(self, x, mask):\n","        out = self.multi_head_attention_layer(query=x, key=x, value=x, mask=mask)\n","        out = self.position_wise_feed_forward_layer(x=out)\n","        return out"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"swPLqmZMAIuc"},"source":["class DecoderLayer(nn.Module):\n","    \n","    def __init__(self, masked_multi_head_attention_layer, multi_head_attention_layer, position_wise_feed_forward_layer, norm_layer, dropout_rate):\n","        super(DecoderLayer, self).__init__()\n","        self.masked_multi_head_attention_layer = ResidualConnectionLayer(multi_head_attention_layer, copy.deepcopy(norm_layer), dropout_rate)\n","        self.multi_head_attention_layer = ResidualConnectionLayer(masked_multi_head_attention_layer, copy.deepcopy(norm_layer), dropout_rate)\n","        self.position_wise_feed_forward_layer = ResidualConnectionLayer(position_wise_feed_forward_layer, copy.deepcopy(norm_layer), dropout_rate)\n","    \n","    def forward(self, x, mask, encoder_output, encoder_mask):\n","        out = self.masked_multi_head_attention_layer(query=x, key=x, value=x, mask=mask)\n","        out = self.multi_head_attention_layer(query=out, key=encoder_output, value=encoder_output, mask=encoder_mask)\n","        out = self.position_wise_feed_forward_layer(x=out)\n","        return out"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"4ip2IS88AIuc"},"source":["class MultiHeadAttentionLayer(nn.Module):\n","    \n","    def __init__(self, d_model, n_head, qkv_fc_layer, fc_layer, dropout_rate):\n","        super(MultiHeadAttentionLayer, self).__init__()\n","        self.d_model = d_model\n","        self.n_head = n_head\n","        self.query_fc_layer = copy.deepcopy(qkv_fc_layer)\n","        self.key_fc_layer = copy.deepcopy(qkv_fc_layer)\n","        self.value_fc_layer = copy.deepcopy(qkv_fc_layer)\n","        self.fc_layer = fc_layer\n","        self.dropout = nn.Dropout(dropout_rate)\n","    \n","    def forward(self, query, key, value, mask=None):\n","        # query, key, value's shape: (n_batch, seq_len, d_embed)\n","        n_batch = query.shape[0]\n","        \n","        # reshape (n_batch, seq_len, d_embed) to (n_batch, n_head, seq_len, d_k)\n","        def transform(x, fc_layer):\n","            # x's shape: (n_batch, seq_len, d_embed)\n","            out = fc_layer(x) # d_embed -> d_model, out's shape: (n_batch, seq_len, d_model)\n","            out = out.view(n_batch, -1, self.n_head, self.d_model//self.n_head) # out's shape: (n_batch, seq_len, n_head, d_k) notice: d_k == d_model//n_head\n","            out = out.transpose(1, 2) # out's shape: (n_batch, n_head, seq_len, d_k)\n","            return out\n","        \n","        query = transform(query, self.query_fc_layer)      # query, key, value's shape: (n_batch, n_head, seq_len, d_k)\n","        key = transform(key, self.key_fc_layer)\n","        value = transform(value, self.value_fc_layer)\n","        \n","        if mask is not None:\n","            mask = mask.unsqueeze(1)\n","            \n","        out = self.calculate_attention(query, key, value, mask, self.dropout) # out's shape: (n_batch, n_head, seq_len, d_k)\n","        out = out.transpose(1, 2)  # out's shape: (n_batch, seq_len, n_head, d_k)\n","        out = out.contiguous().view(n_batch, -1, self.d_model)  # out's shape: (n_batch, seq_len, d_model)\n","        out = self.fc_layer(out)  # d-model -> d_embed, out's shape: (n_batch, seq_len, d_embed)\n","        return out\n","    \n","    def calculate_attention(self, query, key, value, mask, dropout=None): \n","        d_k = key.size(-1) # query, key, value's shape: (n_batch, n_head, seq_len, d_k)\n","        score = torch.matmul(query, key.transpose(-2, -1)) # Q x K^T\n","        score = score / math.sqrt(d_k)  # scaling\n","        if mask is not None:\n","            score = score.masked_fill(mask==0, -1e9)  # masking (Decoder's Masked Multi-Attention Layer)\n","        out = F.softmax(score, dim = -1) # get softmax score\n","        if dropout is not None:\n","            out = dropout(out)\n","        out = torch.matmul(out, value) # score x V\n","        return out"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"Deq3hwdsXYFf"},"source":["class PositionWiseFeedForwardLayer(nn.Module):\n","    def __init__(self, first_fc_layer, second_fc_layer, dropout_rate):\n","        super(PositionWiseFeedForwardLayer, self).__init__()\n","        self.first_fc_layer = first_fc_layer\n","        self.second_fc_layer = second_fc_layer\n","        self.dropout = nn.Dropout(dropout_rate)\n","    \n","    def forward(self, **kwargs):\n","        x = kwargs['x']\n","        out = self.first_fc_layer(x)\n","        out = F.relu(out)\n","        out = self.dropout(out)\n","        out = self.second_fc_layer(out)\n","        return out"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"_2P5B3anAIud"},"source":["class ResidualConnectionLayer(nn.Module):\n","    def __init__(self, sub_layer, norm_layer, dropout_rate):\n","        super(ResidualConnectionLayer, self).__init__()\n","        self.sub_layer = sub_layer\n","        self.norm_layer = norm_layer\n","        self.dropout = nn.Dropout(dropout_rate)\n","    \n","    def forward(self, **kwargs):\n","        if 'x' in kwargs.keys():\n","            x = kwargs['x']\n","        elif 'query' in kwargs.keys():\n","            x = kwargs['query']\n","        out = x + self.dropout(self.sub_layer(**kwargs))\n","        out = self.norm_layer(out)\n","        return out"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"cdJNf7S0AIud"},"source":["class PositionalEncoding(nn.Module):\n","    def __init__(self, d_embed, dropout_rate, max_seq_len=5000):\n","        super(PositionalEncoding, self).__init__()\n","        encoding = torch.zeros(max_seq_len, d_embed)\n","        position = torch.arange(0, max_seq_len).unsqueeze(1)\n","        div_term = torch.exp(torch.arange(0, d_embed, 2) * -(math.log(10000.0) / d_embed))\n","        encoding[:, 0::2] = torch.sin(position * div_term)\n","        encoding[:, 1::2] = torch.cos(position * div_term)\n","        encoding = encoding.unsqueeze(0)\n","        self.encoding = encoding\n","        self.dropout = nn.Dropout(dropout_rate)\n","        \n","    def forward(self, x):\n","        out = x + Variable(self.encoding[:, :x.size(1)], requires_grad=False).to(device)\n","        out = self.dropout(out)\n","        return out"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"6ugo2ItlAIud"},"source":["class Embedding(nn.Module):\n","    def __init__(self, d_embed, vocab):\n","        super(Embedding, self).__init__()\n","        self.embedding = nn.Embedding(len(vocab), d_embed)\n","        self.vocab = vocab\n","        self.d_embed = d_embed\n","    \n","    def forward(self, x):\n","        out = self.embedding(x) * math.sqrt(self.d_embed)\n","        return out"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"AREKJEneAIud"},"source":["class TransformerEmbedding(nn.Module):\n","    def __init__(self, embedding, positional_encoding):\n","        super(TransformerEmbedding, self).__init__()\n","        self.embedding = nn.Sequential(embedding, positional_encoding)\n","    \n","    def forward(self, x):\n","        out = self.embedding(x)\n","        return out"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"AY7GFu2fAIud"},"source":["def make_model(\n","    src_vocab, \n","    trg_vocab, \n","    d_embed = 512, \n","    n_layer = 6, \n","    d_model = 512, \n","    n_head = 8, \n","    d_ff = 2048,\n","    dropout_rate = 0.1):\n","\n","    cp = lambda x : copy.deepcopy(x).to(device)\n","\n","    multi_head_attention_layer = MultiHeadAttentionLayer(\n","                                    d_model = d_model,\n","                                    n_head = n_head,\n","                                    qkv_fc_layer = nn.Linear(d_embed, d_model),\n","                                    fc_layer = nn.Linear(d_model, d_embed),\n","                                    dropout_rate = dropout_rate)\n","    \n","    position_wise_feed_forward_layer = PositionWiseFeedForwardLayer(\n","                                         first_fc_layer = nn.Linear(d_embed, d_ff),\n","                                         second_fc_layer = nn.Linear(d_ff, d_embed),\n","                                         dropout_rate = dropout_rate)\n","    \n","    norm_layer = nn.LayerNorm(d_embed, eps=1e-6)\n","\n","    model = Transformer(\n","                src_embed = TransformerEmbedding(\n","                                embedding = Embedding(\n","                                                d_embed = d_embed, \n","                                                vocab = src_vocab), \n","                                positional_encoding = PositionalEncoding(\n","                                                d_embed = d_embed,\n","                                                dropout_rate = dropout_rate)), \n","                trg_embed = TransformerEmbedding(\n","                                embedding = Embedding(\n","                                                d_embed = d_embed, \n","                                                vocab = trg_vocab), \n","                                positional_encoding = PositionalEncoding(\n","                                                d_embed = d_embed,\n","                                                dropout_rate = dropout_rate)),\n","                encoder = Encoder(\n","                                sub_layer = EncoderLayer(\n","                                                multi_head_attention_layer = cp(multi_head_attention_layer),\n","                                                position_wise_feed_forward_layer = cp(position_wise_feed_forward_layer),\n","                                                norm_layer = cp(norm_layer),\n","                                                dropout_rate = dropout_rate),\n","                                n_layer = n_layer),\n","                decoder = Decoder(\n","                                sub_layer = DecoderLayer(\n","                                                masked_multi_head_attention_layer = cp(multi_head_attention_layer),\n","                                                multi_head_attention_layer = cp(multi_head_attention_layer),\n","                                                position_wise_feed_forward_layer = cp(position_wise_feed_forward_layer),\n","                                                norm_layer = cp(norm_layer),\n","                                                dropout_rate = dropout_rate),\n","                                n_layer = n_layer),\n","                fc_layer = nn.Linear(d_model, len(trg_vocab)).to(device))\n","    \n","    return model"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"McJYJOZtAIuZ"},"source":["# Vocab"]},{"cell_type":"code","metadata":{"id":"ew6YXWk3AIua"},"source":["from torchtext.data import Field\n","import spacy\n","\n","SRC = Field(tokenize = 'spacy',\n","            tokenizer_language='en',\n","            init_token = '<sos>',\n","            pad_token = '<pad>',\n","            eos_token = '<eos>',\n","            unk_token = '<unk>',\n","            lower=True\n","            )\n","\n","TRG = Field(tokenize = 'spacy',\n","            tokenizer_language='de',\n","            init_token = '<sos>',\n","            pad_token = '<pad>',\n","            eos_token = '<eos>',\n","            unk_token = '<unk>',\n","            lower=True\n","            )  "],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"_L54xQonLkDH"},"source":["import pickle\n","\n","def save_vocab(vocab, path):\n","    with open(path, 'wb') as f:\n","        pickle.dump(vocab, f)\n","\n","def load_vocab(path):\n","    with open(path, 'rb') as f:\n","        vocab = pickle.load(f)\n","    return vocab"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"cxNYzVSvLlPE"},"source":["SRC.vocab = load_vocab('wmt14/src.vocab')\n","TRG.vocab = load_vocab('wmt14/trg.vocab')"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"Um2wcEc1AIuf"},"source":["# Batch & Traniner"]},{"cell_type":"code","metadata":{"id":"Y9X2bhJTAIue"},"source":["class Batch:\n","    \n","    \"Object for holding a batch of data with masking during training.\" \n","    def __init__(self, src, trg=None, pad=1):\n","        self.src = src.T\n","        self.src_mask = (self.src != pad).unsqueeze(-2)  # source mask, <pad>: False, other tokens: True\n","        if trg is not None:\n","            self.trg = trg.T[:, :-1]  # target sentence 0 ~ -1\n","            self.trg_y = trg.T[:, 1:]  # target sentence 1 ~ end\n","            self.trg_mask = self.make_std_mask(self.trg, pad) # target mask\n","            self.lengths = torch.sum((self.trg_y != pad), dim=1)\n","            self.ntokens = (self.trg_y != pad).data.sum() # number of tokens\n","    \n","    def __len__(self):\n","        return len(self.src)\n","\n","    def subsequent_mask(self, size):\n","        \"Mask out subsequent positions.\"\n","        attn_shape = (1, size, size)\n","        mask = np.triu(np.ones(attn_shape), k=1).astype('uint8')  # masking with upper triangle\n","        return torch.from_numpy(mask) == 0 # reverse (masking=False, non-masking=True)\n","    \n","    def make_std_mask(self, tgt, pad):\n","        \"Create a mask to hide padding and future words.\"\n","        tgt_mask = (tgt != pad).unsqueeze(-2) # <pad>: False, other tokens: True, reshape (batch_size, seq_len) -> (batch_size, 1, seq_len)\n","        tgt_mask = tgt_mask & Variable(self.subsequent_mask(tgt.size(-1)).type_as(tgt_mask.data)) # not <pad> && non-masking: True, others: False\n","        return tgt_mask"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"QTRM9ncSS7Dk"},"source":["import json\n","import GPUtil\n","from torchtext import data\n","from torchtext.data import Dataset, BucketIterator\n","import nltk.translate.bleu_score as bleu\n","\n","class Trainer:\n","    def __init__(self,\n","                 device,\n","                 model,\n","                 src_field,\n","                 trg_field,\n","                 batch_size,\n","                 criterion,\n","                 optimizer,\n","                 train_dataset_path,\n","                 valid_dataset_path,\n","                 test_dataset_path,\n","                 check_point_path='./'):\n","       self.model = model\n","       self.device = device\n","       self.batch_size = batch_size\n","       self.criterion = criterion\n","       self.optimizer = optimizer\n","       self.src_field = src_field\n","       self.trg_field = trg_field\n","       self.src_vocab = self.src_field.vocab\n","       self.trg_vocab = self.trg_field.vocab\n","       self.train_dataset_path = [train_dataset_path] if type(train_dataset_path) is str else train_dataset_path\n","       self.valid_dataset_path = valid_dataset_path\n","       self.test_dataset_path = test_dataset_path\n","       self.check_point_path = check_point_path\n","       self.now_epoch = 1\n","       self.now_train_split_num = 1\n","       self.train_split_loss = 0\n","       self.train_split_bleu_score = 0\n","       self.train_loss = []\n","       self.train_bleu_score = []\n","       self.valid_loss = []\n","       self.valid_bleu_score = []\n","       self.test_loss = 0\n","       self.test_bleu_score = 0\n","       \n","    def itos(self, field, batch):  # batch에서 원본 sentence 얻는 함수\n","        with torch.cuda.device_of(batch):\n","            batch = batch.tolist()\n","        batch = [[field.vocab.itos[ind] for ind in ex] for ex in batch]  # denumericalize\n","        \n","        def trim(s, t):  # 현재 token ~ <EOS> token 사이의 문장 return\n","            sentence = []\n","            for w in s:\n","                if w == t:\n","                    break\n","                sentence.append(w)\n","            return sentence\n","\n","        batch = [trim(ex, field.eos_token) for ex in batch]  # batch를 문장으로 \n","        \n","        def filter_special(tok):\n","            return tok not in (field.init_token, field.pad_token)\n","\n","        batch = [' '.join(list(filter(filter_special, ex))) for ex in batch]\n","        return batch\n","    \n","    def load_dataset(self, filename, print_time=False):\n","        def load_examples(filename):\n","            examples = []\n","            if print_time:\n","                start = time.time()\n","            with open(filename, 'r') as f:\n","                # Read num. elements (not really need it)\n","                total = json.loads(f.readline())\n","                # Save elements\n","                for i in range(total):\n","                    line = f.readline()\n","                    example = json.loads(line)\n","                    # example = data.Example().fromlist(example, fields)  # Create Example obj. (you can do it here or later)\n","                    examples.append(example)\n","            if print_time:\n","                end = time.time()\n","                print(end - start)\n","            return examples\n","\n","        fields = [('src', self.src_field), ('trg', self.trg_field)]\n","        data_list = load_examples(filename)\n","        data_list = [data.Example().fromlist(d, fields) for d in data_list]\n","        return Dataset(data_list, fields)\n","\n","    def save_status(self):\n","        epoch = self.now_epoch\n","        train_split_num = self.now_train_split_num-1\n","        if self.now_train_split_num == 1:\n","            epoch -= 1\n","            train_split_num = len(self.train_dataset_path)\n","        check_point_path = \"%s/%d_%d.pt\" % (self.check_point_path, epoch, train_split_num)\n","        torch.save({\n","            'model': self.model.state_dict(),\n","            'optimizer': self.optimizer.state_dict(),\n","            'now_epoch': self.now_epoch,\n","            'now_train_split_num': self.now_train_split_num,\n","            'train_loss': self.train_loss,\n","            'train_bleu_score': self.train_bleu_score,\n","            'valid_loss': self.valid_loss,\n","            'valid_bleu_score': self.valid_bleu_score\n","        }, check_point_path)\n","        print(\"%s is saved\" % check_point_path)\n","\n","    def load_status(self, check_point_path):\n","        check_point = torch.load(check_point_path)\n","        self.model.load_state_dict(check_point['model'])\n","        self.optimizer.load_state_dict(check_point['optimizer'])\n","        self.now_epoch = check_point['now_epoch']\n","        self.now_train_split_num = check_point['now_train_split_num']\n","        self.train_loss = check_point['train_loss']\n","        self.train_bleu_score = check_point['train_bleu_score']\n","        self.valid_loss = check_point['valid_loss']\n","        self.valid_bleu_score = check_point['valid_bleu_score']\n","        print(\"%s is loaded\" % check_point_path)\n","    \n","    def get_batch_bleu_score(self, pred, label):\n","        assert len(pred) == len(label) # same batch size\n","        score = 0\n","        cnt = 0\n","        for (x, y) in zip(pred, label):\n","            if len(x) > 1 and len(y) > 1:\n","                score += bleu.sentence_bleu([y.split()], x.split(), smoothing_function=bleu.SmoothingFunction().method3)\n","                cnt += 1\n","        score /= cnt\n","        return score\n","    \n","    def train(self, n_epoch, valid=True, save=False, log_interval=200):\n","        for epoch in range(self.now_epoch, self.now_epoch+n_epoch):\n","            self.model.train()\n","            print(\"\\n\\n******[Train Epoch: %d Start]*****\\n\\n\" % (epoch))\n","            total_loss = self.train_split_loss\n","            total_bleu_score = self.train_split_bleu_score\n","            pad_index = self.trg_vocab['<pad>']\n","            batch_cnt = 0\n","\n","            for idx in range(self.now_train_split_num, len(self.train_dataset_path)+1):\n","                file_path = self.train_dataset_path[idx-1]\n","                train_dataset = self.load_dataset(file_path)\n","                train_iterator = BucketIterator(train_dataset, batch_size=self.batch_size, device=self.device)\n","                print('\\n[%s is loaded]\\n' % (file_path))\n","\n","                for i, batch_without_mask in enumerate(train_iterator):\n","                    batch_cnt += 1\n","                    # mask 적용\n","\n","                    batch = Batch(batch_without_mask.src, batch_without_mask.trg, pad_index)\n","\n","                    batch.src = batch.src.to(device)\n","                    batch.trg = batch.trg.to(device)\n","                    batch.src_mask = batch.src_mask.to(device)\n","                    batch.trg_mask = batch.trg_mask.to(device)\n","\n","                    out = self.model.forward(batch.src, batch.trg, batch.src_mask, batch.trg_mask)\n","\n","                    loss = self.criterion(out.contiguous().transpose(-2, -1), batch.trg_y.contiguous())\n","\n","                    self.optimizer.zero_grad()\n","                    loss.backward()\n","                    self.optimizer.step()\n","                    total_loss += float(loss)\n","\n","                    out_sentences = self.itos(self.trg_field, torch.argmax(F.log_softmax(out, dim=-1),dim=-1))\n","                    label_sentences = self.itos(self.trg_field, batch.trg_y)\n","                    total_bleu_score += float(self.get_batch_bleu_score(out_sentences, label_sentences))\n","\n","                    if batch_cnt % log_interval == 0:\n","                        print(\"[%d'th Batch]\\nLoss: %f\\tBLEU Score: %f\" % (batch_cnt, total_loss / batch_cnt, total_bleu_score / batch_cnt))\n","                        GPUtil.showUtilization()\n","                        print()\n","                self.now_train_split_num += 1\n","                self.train_split_loss = total_loss\n","                self.train_split_bleu_score = total_bleu_score\n","                if self.now_train_split_num <= len(self.train_dataset_path):\n","                    if save:\n","                        self.save_status()\n","\n","            loss_avr = total_loss / batch_cnt\n","            bleu_avr = total_bleu_score / batch_cnt\n","            self.train_loss.append(loss_avr)\n","            self.train_bleu_score.append(bleu_avr)\n","            print(\"[Train Epoch: %d]\\nLoss: %f\\tBLEU Score: %f\" % (epoch, loss_avr, bleu_avr))\n","            if valid:\n","                del out\n","                del loss\n","                del total_loss\n","                del train_dataset\n","                del train_iterator\n","                del out_sentences\n","                del label_sentences\n","                del total_bleu_score\n","                self.evaluation(is_valid=True)\n","            self.now_epoch += 1\n","            self.now_train_split_num = 1\n","            self.train_split_loss = 0\n","            self.train_split_bleu_score = 0\n","            if save:\n","                self.save_status()\n","\n","        return loss_avr, bleu_avr\n","\n","    def evaluation(self, is_valid=True, log_interval=200):\n","        self.model.eval()\n","        valid_dataset = self.load_dataset(valid_dataset_path, self.src_vocab, self.trg_vocab)\n","        valid_iterator = BucketIterator(valid_dataset, batch_size = self.batch_size, device = self.device)\n","        for epoch in range(n_epoch):\n","            if is_valid:\n","                print(\"\\n\\n******[Validation Start]*****\\n\\n\")\n","            else:\n","                print(\"\\n\\n******[Test Start]*****\\n\\n\")\n","            total_loss = 0\n","            pad_index = self.trg_vocab['<pad>']\n","            total_bleu_score = 0\n","            batch_cnt = 0\n","\n","            file_path = self.validation_dataset_path if is_valid else self.test_dataset_path\n","            eval_dataset = self.load_dataset(file_path)\n","            eval_iterator = BucketIterator(eval_dataset, batch_size=self.batch_size, device=self.device)\n","\n","            for i, batch_without_mask in enumerate(eval_iterator):\n","                batch_cnt += 1\n","                # mask 적용\n","\n","                batch = Batch(batch_without_mask.src, batch_without_mask.trg, pad_index)\n","\n","                batch.src = batch.src.to(device)\n","                batch.trg = batch.trg.to(device)\n","                batch.src_mask = batch.src_mask.to(device)\n","                batch.trg_mask = batch.trg_mask.to(device)\n","\n","                out = self.model.forward(batch.src, batch.trg, batch.src_mask, batch.trg_mask)\n","\n","                loss = self.criterion(out.contiguous().transpose(-2, -1), batch.trg_y.contiguous())\n","\n","                total_loss += float(loss)\n","\n","                out_sentences = self.itos(TRG, torch.argmax(F.log_softmax(out, dim=-1),dim=-1))\n","                label_sentences = self.itos(TRG, batch.trg_y)\n","                total_bleu_score += float(self.get_batch_bleu_score(out_sentences, label_sentences))\n","\n","                if batch_cnt % log_interval == 0:\n","                    print(\"[%d'st Batch]\\nLoss: %f\\tBLEU Score: %f\" % (batch_cnt, total_loss / batch_cnt, total_bleu_score / batch_cnt))\n","                    GPUtil.showUtilization()\n","                    print()\n","\n","        loss_avr = total_loss / batch_cnt\n","        bleu_avr = total_bleu_score / batch_cnt\n","        if is_valid:\n","            self.valid_loss.append(loss_avr)\n","            self.valid_bleu_score.append(bleu_avr)\n","        else:\n","            self.test_loss = loss_avr\n","            self.test_bleu_score = bleu_avr\n","        return loss_avr, bleu_avr"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"xAo82IMQ5Qlu"},"source":["class LabelSmoothing(nn.Module):\n","    \"Implement label smoothing.\"\n","    def __init__(self, size, padding_idx, smoothing=0.0):\n","        super(LabelSmoothing, self).__init__()\n","        self.criterion = nn.KLDivLoss(reduction='sum')\n","        self.padding_idx = padding_idx\n","        self.confidence = 1.0 - smoothing\n","        self.smoothing = smoothing\n","        self.size = size # vocab size\n","        self.true_dist = None\n","        \n","    def forward(self, x, target):\n","        # x: (n_batch, n_vocab, seq), target: (n_batch, seq)\n","        x = x.cpu()\n","        target = target.cpu()\n","        assert x.size(1) == self.size # vocab size correct\n","        true_dist = x.data.clone() # (n_batch, n_vocab, seq)\n","        true_dist.fill_(self.smoothing / (self.size - 2)) # fill with smoothing (2: except correct, pad)\n","        confidence = x.data.clone()\n","        confidence = confidence.fill_(self.confidence)\n","        true_dist.scatter_(dim=1, index=target.data.unsqueeze(1), src=confidence) # scatter confidence with target(per dim=1)\n","        true_dist[:, self.padding_idx] = 0 # pad index's prob: 0\n","        mask = torch.BoolTensor(target.data != self.padding_idx) # padding_index: False, else: True\n","        true_dist = true_dist * mask.unsqueeze(1) # pad masking to true_dist\n","        self.true_dist = true_dist\n","        avr_loss = self.criterion(x, Variable(true_dist, requires_grad=False)) / float(mask.data.sum())\n","        return avr_loss"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"gQdxLVbsRzKd"},"source":["# Train"]},{"cell_type":"code","metadata":{"id":"sxt1Smj9AIuf"},"source":["model = make_model(SRC.vocab, TRG.vocab, d_embed=512, n_layer=6, d_model=512, n_head=8, d_ff=2048)\n","model.to(device)\n","print(model)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"y7O0zt9alZJP"},"source":["batch_size = 32\n","learning_rate  = 0.01\n","optimizer = optim.Adam(model.parameters(), lr=learning_rate, betas=(0.9, 0.98), eps=1e-9)\n","criterion = LabelSmoothing(size=len(TRG.vocab), padding_idx=TRG.vocab['<pad>'], smoothing=0.1).to(device)\n","\n","dataset_dir_path = './wmt14/'\n","\n","train_dataset_path = ['%strain_%02d.json' % (dataset_dir_path, i+1) for i in range(9)]\n","\n","trainer = Trainer(device = device,\n","                 model = model,\n","                 src_field = SRC,\n","                 trg_field = TRG,\n","                 batch_size = batch_size,\n","                 criterion = criterion,\n","                 optimizer = optimizer,\n","                 train_dataset_path = train_dataset_path,\n","                 valid_dataset_path = dataset_dir_path + 'valid.json',\n","                 test_dataset_path = dataset_dir_path + 'test.json',\n","                 check_point_path='./save')"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"mkivFuLkrCRn"},"source":["import warnings\n","warnings.filterwarnings('ignore')\n","\n","trainer.train(n_epoch=5, valid=True, save=True, log_interval=200)"],"execution_count":null,"outputs":[]}]}